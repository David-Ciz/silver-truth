{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6151ef9a-d708-426c-9335-62634ebad81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import to_rgba\n",
    "from collections import defaultdict\n",
    "import pathlib\n",
    "import tifffile\n",
    "from sklearn.metrics import jaccard_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def analyze_contrasting_performance(df, overall_scores, output_dir=\"plots\"):\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = pathlib.Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # First, incorporate silver truth into the DataFrame\n",
    "    enhanced_df = create_silver_truth_df(overall_scores, df)\n",
    "    \n",
    "    # Then proceed with the analysis\n",
    "    cases = find_contrasting_cases(enhanced_df)\n",
    "    \n",
    "    if not cases:\n",
    "        print(\"No contrasting cases found!\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nTop Contrasting Performance Cases:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, case in enumerate(cases[:3], 1):\n",
    "        case_name = case['image'].split('/')[-1].replace('.', '_')\n",
    "        print(f\"\\nCase {i}:\")\n",
    "        print(f\"Image: {case['image'].split('/')[-1]}\")\n",
    "        print(f\"Competitors: {case['competitor1']} vs {case['competitor2']}\")\n",
    "        print(f\"Contrast Magnitude: {case['contrast_magnitude']:.3f}\")\n",
    "        \n",
    "        # Create all five plot variants\n",
    "        plot_variants = [\n",
    "            {\n",
    "                'name': 'all_competitors',\n",
    "                'params': {'show_all': True, 'include_silver_truth': False},\n",
    "                'title': f\"Case {i}: All Competitor Models\"\n",
    "            },\n",
    "            {\n",
    "                'name': 'contrasting_pair',\n",
    "                'params': {'show_all': False, 'include_silver_truth': False},\n",
    "                'title': f\"Case {i}: Contrasting Competitors Highlighted\"\n",
    "            },\n",
    "            {\n",
    "                'name': 'all_with_silver',\n",
    "                'params': {'show_all': True, 'include_silver_truth': True},\n",
    "                'title': f\"Case {i}: All Competitors with Silver Truth\"\n",
    "            },\n",
    "            {\n",
    "                'name': 'silver_highlighted',\n",
    "                'params': {'show_all': False, 'include_silver_truth': True, 'highlight_silver': True},\n",
    "                'title': f\"Case {i}: Silver Truth Highlighted\"\n",
    "            },\n",
    "            {\n",
    "                'name': 'best_highlighted',\n",
    "                'params': {'show_all': True, 'highlight_best': True},\n",
    "                'title': f\"Case {i}: Best Performers Highlighted\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        for variant in plot_variants:\n",
    "            plt.figure(figsize=(15, 8))  # Larger figure size to accommodate legend\n",
    "            visualize_case(case, enhanced_df, **variant['params'])\n",
    "            plt.title(variant['title'])\n",
    "            \n",
    "            # Save plot with descriptive filename\n",
    "            filename = f\"case_{i}_{case_name}_{variant['name']}.png\"\n",
    "            filepath = output_dir / filename\n",
    "            plt.savefig(filepath, bbox_inches='tight', dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Saved plot: {filename}\")\n",
    "            \n",
    "    return cases, enhanced_df\n",
    "\n",
    "def visualize_case(case, df, max_labels=10, show_all=False, include_silver_truth=True, highlight_silver=False, highlight_best=False):\n",
    "    \"\"\"\n",
    "    Enhanced visualization function with label limitation and multiple display options.\n",
    "    \"\"\"\n",
    "    comp1 = case['competitor1']\n",
    "    comp2 = case['competitor2']\n",
    "    image = case['image']\n",
    "    image_data = df[df['Gt_source_file'] == image]\n",
    "    image_data = image_data[image_data['J_value'] > 0.001]\n",
    "    \n",
    "    all_competitors = sorted(comp for comp in image_data['competitor_name'].unique() \n",
    "                           if comp != 'Silver Truth')\n",
    "    \n",
    "    # Select most interesting labels\n",
    "    label_interests = []\n",
    "    all_labels = sorted(image_data['Label'].unique())\n",
    "    \n",
    "    for label in all_labels:\n",
    "        label_data = image_data[image_data['Label'] == label]\n",
    "        scores_dict = {row['competitor_name']: row['J_value'] \n",
    "                      for _, row in label_data.iterrows()}\n",
    "        \n",
    "        # Calculate variance of scores for this label (excluding silver truth)\n",
    "        scores = [v for k, v in scores_dict.items() if k != 'Silver Truth']\n",
    "        variance = np.var(scores) if scores else 0\n",
    "        \n",
    "        # Calculate difference between main competitors if both present\n",
    "        main_diff = 0\n",
    "        if comp1 in scores_dict and comp2 in scores_dict:\n",
    "            main_diff = abs(scores_dict[comp1] - scores_dict[comp2])\n",
    "        \n",
    "        # Calculate maximum score difference between any competitors\n",
    "        max_diff = 0\n",
    "        if scores:\n",
    "            max_diff = max(scores) - min(scores)\n",
    "        \n",
    "        # Combine factors for interestingness\n",
    "        interestingness = variance + main_diff + max_diff\n",
    "        label_interests.append((label, interestingness))\n",
    "    \n",
    "    # Sort by interestingness and take top max_labels\n",
    "    label_interests.sort(key=lambda x: x[1], reverse=True)\n",
    "    selected_labels = [label for label, _ in label_interests[:max_labels]]\n",
    "    selected_labels.sort()  # Sort labels numerically for consistent display\n",
    "    \n",
    "    # Create label mapping\n",
    "    label_to_seq = {label: idx + 1 for idx, label in enumerate(selected_labels)}\n",
    "    seq_to_label = {idx + 1: label for idx, label in enumerate(selected_labels)}\n",
    "    \n",
    "    # For highlighting best performers\n",
    "    if highlight_best:\n",
    "        best_scores = {}\n",
    "        for label in selected_labels:\n",
    "            label_data = image_data[image_data['Label'] == label]\n",
    "            if not label_data.empty:\n",
    "                max_score = label_data['J_value'].max()\n",
    "                best_scores[label] = set(label_data[label_data['J_value'] == max_score]['competitor_name'])\n",
    "    \n",
    "    # Plot competitors\n",
    "    if show_all:\n",
    "        colors = plt.cm.tab20(np.linspace(0, 1, len(all_competitors)))\n",
    "        for idx, competitor in enumerate(all_competitors):\n",
    "            comp_data = image_data[image_data['competitor_name'] == competitor]\n",
    "            scores = []\n",
    "            x_values = []\n",
    "            \n",
    "            for label in selected_labels:  # Use selected_labels instead of all_labels\n",
    "                label_score = comp_data[comp_data['Label'] == label]['J_value']\n",
    "                if not label_score.empty and label_score.iloc[0] > 0.001:\n",
    "                    scores.append(label_score.iloc[0])\n",
    "                    x_values.append(label_to_seq[label])\n",
    "            \n",
    "            if scores:\n",
    "                if highlight_best:\n",
    "                    has_best = any(competitor in best_scores.get(label, set()) for label in selected_labels)\n",
    "                    alpha = 1.0 if has_best else 0.2\n",
    "                    linewidth = 2.5 if has_best else 1\n",
    "                    label = f\"{competitor} {'(Best)' if has_best else ''}\"\n",
    "                else:\n",
    "                    alpha = 1.0\n",
    "                    linewidth = 2\n",
    "                    label = competitor\n",
    "                \n",
    "                plt.plot(x_values, scores, '-o', color=colors[idx], \n",
    "                        label=label, linewidth=linewidth, markersize=6,\n",
    "                        alpha=alpha)\n",
    "    else:\n",
    "        # Plot non-highlighted competitors\n",
    "        for competitor in all_competitors:\n",
    "            if competitor not in [comp1, comp2]:\n",
    "                comp_data = image_data[image_data['competitor_name'] == competitor]\n",
    "                scores = []\n",
    "                x_values = []\n",
    "                \n",
    "                for label in selected_labels:  # Use selected_labels instead of all_labels\n",
    "                    label_score = comp_data[comp_data['Label'] == label]['J_value']\n",
    "                    if not label_score.empty and label_score.iloc[0] > 0.001:\n",
    "                        scores.append(label_score.iloc[0])\n",
    "                        x_values.append(label_to_seq[label])\n",
    "                \n",
    "                if scores:\n",
    "                    plt.plot(x_values, scores, '-o', color='gray', alpha=0.2, \n",
    "                            linewidth=1, markersize=4, label=competitor)\n",
    "        \n",
    "        # Plot highlighted competitors\n",
    "        if not highlight_silver:\n",
    "            for competitor, color in [(comp1, '#FF6B6B'), (comp2, '#4ECDC4')]:\n",
    "                comp_data = image_data[image_data['competitor_name'] == competitor]\n",
    "                scores = []\n",
    "                x_values = []\n",
    "                \n",
    "                for label in selected_labels:  # Use selected_labels instead of all_labels\n",
    "                    label_score = comp_data[comp_data['Label'] == label]['J_value']\n",
    "                    if not label_score.empty and label_score.iloc[0] > 0.001:\n",
    "                        scores.append(label_score.iloc[0])\n",
    "                        x_values.append(label_to_seq[label])\n",
    "                \n",
    "                if scores:\n",
    "                    plt.plot(x_values, scores, '-o', color=color, \n",
    "                            label=f\"{competitor} (Highlighted)\", linewidth=2.5, markersize=8)\n",
    "    \n",
    "    # Plot silver truth if included\n",
    "    if include_silver_truth:\n",
    "        st_data = image_data[image_data['competitor_name'] == 'Silver Truth']\n",
    "        st_scores = []\n",
    "        st_x_values = []\n",
    "        \n",
    "        for label in selected_labels:  # Use selected_labels instead of all_labels\n",
    "            st_score = st_data[st_data['Label'] == label]['J_value']\n",
    "            if not st_score.empty and st_score.iloc[0] > 0.001:\n",
    "                st_scores.append(st_score.iloc[0])\n",
    "                st_x_values.append(label_to_seq[label])\n",
    "        \n",
    "        if st_scores:\n",
    "            st_style = {'color': 'gold', 'linewidth': 2.5, 'markersize': 12, \n",
    "                       'alpha': 1.0 if highlight_silver else 0.8}\n",
    "            label = 'Silver Truth (Highlighted)' if highlight_silver else 'Silver Truth'\n",
    "            plt.plot(st_x_values, st_scores, '-*', label=label, **st_style)\n",
    "    \n",
    "    # Formatting\n",
    "    plt.xlabel('Sequential Label Number (Original Label)')\n",
    "    plt.ylabel('Jaccard Score')\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    \n",
    "    # Place legend outside the plot\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    # Convert J_values to float and handle the y-axis limits\n",
    "    #valid_scores = pd.to_numeric(image_data['J_value'], errors='coerce')\n",
    "    valid_scores = image_data['J_value'][image_data['J_value'] > 0.001]\n",
    "    print(valid_scores)\n",
    "    if not valid_scores.empty:\n",
    "        plt.ylim(max(0, valid_scores.min() - 0.1), min(1, valid_scores.max() + 0.1))\n",
    "    \n",
    "    x_ticks = list(label_to_seq.values())\n",
    "    plt.xticks(x_ticks, [f'{seq} ({seq_to_label[seq]})' for seq in x_ticks], rotation=45)\n",
    "    plt.xlim(min(x_ticks) - 0.5, max(x_ticks) + 0.5)\n",
    "    \n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "# Usage:\n",
    "# cases, enhanced_df = analyze_contrasting_performance(df, overall_scores, output_dir=\"path/to/save/plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a9ca1bc-3d09-49fe-b07e-1df754c44942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 57/57 [00:36<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "overall_scores = {}\n",
    "for gt_image_path in tqdm(gt_source_files):\n",
    "    synced_gt_image_path = find_gt_image(gt_image_path)\n",
    "    gt_image = tifffile.imread(synced_gt_image_path)\n",
    "    st_image_path = find_silvertruth_image(gt_image_path)\n",
    "    st_image = tifffile.imread(st_image_path)\n",
    "    #print(gt_image_path)\n",
    "    labels = np.unique(gt_image)[1:]\n",
    "    scores = {}\n",
    "    # This is most likely wrong, but let's just have those values shrank to values from 1 to x\n",
    "    for order, label in enumerate(labels):\n",
    "        label_layer = np.zeros_like(gt_image)\n",
    "        label_layer[gt_image == label] = 1\n",
    "        mask_layer = np.zeros_like(st_image) \n",
    "        mask_layer[st_image == label] = 1\n",
    "        j = np.round(jaccard_score(label_layer, mask_layer, average='micro'),6)\n",
    "        scores[order+1] = j\n",
    "    overall_scores[st_image_path] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53392588-b143-4ec5-9a2a-6cefc2a50e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jaccard_scores(gt_image, mask_image):\n",
    "    labels = np.unique(gt_image)[1:]\n",
    "    scores = {}\n",
    "    for label in labels:\n",
    "        label_layer = np.zeros_like(gt_image)\n",
    "        label_layer[gt_image == label] = 1\n",
    "        mask_layer = np.zeros_like(mask_image) \n",
    "        mask_layer[mask_image == label] = 1\n",
    "        j = jaccard_score(label_layer, mask_layer, average='micro')\n",
    "        scores[label] = j\n",
    "    return scores\n",
    "def get_competitor_name(file_path: str):\n",
    "    \"\"\"returns the competitor folder name given a path to a file.\"\"\"\n",
    "    return file_path.split('/')[2]\n",
    "\n",
    "# open corresponding silvertruth:\n",
    "def find_silvertruth_image(gt_image_path: str) -> str:\n",
    "    input_folder, dataset, inner_split, seg, filename = gt_image_path.split('/')\n",
    "    silvertruth_image_path = pathlib.Path(input_folder, dataset, f\"{inner_split.replace('G', 'S')}_sync\", seg, filename)\n",
    "    return str(silvertruth_image_path)\n",
    "\n",
    "def find_gt_image(gt_image_path: str) -> str:\n",
    "    input_folder, dataset, inner_split, seg, filename = gt_image_path.split('/')\n",
    "    synced_gt_image_path = pathlib.Path(input_folder, dataset, f\"{inner_split}_sync\", filename)\n",
    "    return str(synced_gt_image_path)\n",
    "\n",
    "df = pd.read_csv('preprocessed_dataset.csv')\n",
    "df['competitor_name'] = df['Mask_file'].apply(get_competitor_name)\n",
    "\n",
    "\n",
    "gt_source_files = list(df.drop_duplicates(subset=['Gt_mask_file'])['Gt_mask_file'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b9838c9-7bbd-4a25-b3f2-2a6efa938d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_silver_truth_df(overall_scores, df):\n",
    "    \"\"\"Convert silver truth dict to DataFrame matching the structure of the main df\"\"\"\n",
    "    st_rows = []\n",
    "    \n",
    "    for st_image_path, scores in overall_scores.items():\n",
    "        # Extract corresponding GT source file\n",
    "        # gt_source_file = str(pathlib.Path(*st_image_path.split('_ST_sync')[0].split('/')[:-1], \n",
    "        #                                 st_image_path.split('/')[-1]))\n",
    "        input_folder, dataset, inner_split, seg, filename = st_image_path.split('/')\n",
    "        split_number = inner_split.split('_')[0]\n",
    "        filename = filename.replace('man_seg', 't')\n",
    "        gt_source_file = str(pathlib.Path(input_folder, dataset, split_number,filename))\n",
    "        # Extract corresponding GT mask file\n",
    "        input_folder, dataset, inner_split, seg, filename = st_image_path.split('/')\n",
    "        split_number = inner_split.split('_')[0]\n",
    "        gt_mask_file = str(pathlib.Path(input_folder, dataset, f\"{split_number}_GT\", seg, filename))\n",
    "        for label, j_value in scores.items():\n",
    "            st_rows.append({\n",
    "                'Mask_file': st_image_path,\n",
    "                'Gt_source_file': gt_source_file,\n",
    "                'Gt_mask_file': gt_mask_file,\n",
    "                'Label': label,\n",
    "                'J_value': j_value,\n",
    "                'competitor_name': 'Silver Truth'  # Special competitor name for silver truth\n",
    "            })\n",
    "    \n",
    "    st_df = pd.DataFrame(st_rows)\n",
    "    return pd.concat([df, st_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b0b91e7-7253-41bf-9377-b176e2073819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contrasting_cases(df):\n",
    "    \"\"\"Find cases with contrasting performance, ignoring zero values.\"\"\"\n",
    "    # Group data by image\n",
    "    image_data = defaultdict(lambda: defaultdict(dict))\n",
    "    \n",
    "    # Filter out zero values\n",
    "    df_filtered = df[df['J_value'] > 0.001]\n",
    "    \n",
    "    # First, organize data by image -> label -> competitor -> score\n",
    "    for _, row in df_filtered.iterrows():\n",
    "        image = row['Gt_source_file']\n",
    "        label = row['Label']\n",
    "        competitor = row['competitor_name']\n",
    "        score = row['J_value']\n",
    "        image_data[image][label][competitor] = score\n",
    "    \n",
    "    interesting_cases = []\n",
    "    \n",
    "    # Analyze each image\n",
    "    for image, label_data in image_data.items():\n",
    "        # Only consider images with multiple labels\n",
    "        if len(label_data) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Calculate mean score per competitor per label\n",
    "        competitor_label_scores = defaultdict(dict)\n",
    "        for label, comp_scores in label_data.items():\n",
    "            for competitor, score in comp_scores.items():\n",
    "                competitor_label_scores[competitor][label] = score\n",
    "        \n",
    "        # Look for contrasting performance\n",
    "        for comp1 in competitor_label_scores:\n",
    "            for comp2 in competitor_label_scores:\n",
    "                if comp1 >= comp2:\n",
    "                    continue\n",
    "                    \n",
    "                performance_diff = []\n",
    "                for label in label_data:\n",
    "                    # Only consider labels where both competitors have scores\n",
    "                    if label in competitor_label_scores[comp1] and label in competitor_label_scores[comp2]:\n",
    "                        diff = competitor_label_scores[comp1][label] - competitor_label_scores[comp2][label]\n",
    "                        performance_diff.append((label, diff))\n",
    "                \n",
    "                # Check if there are contrasting performances (positive and negative differences)\n",
    "                pos_diffs = [d for _, d in performance_diff if d > 0]\n",
    "                neg_diffs = [d for _, d in performance_diff if d < 0]\n",
    "                \n",
    "                if pos_diffs and neg_diffs:  # If we have both positive and negative differences\n",
    "                    max_contrast = max(pos_diffs) + abs(min(neg_diffs))  # Total contrast magnitude\n",
    "                    \n",
    "                    interesting_cases.append({\n",
    "                        'image': image,\n",
    "                        'competitor1': comp1,\n",
    "                        'competitor2': comp2,\n",
    "                        'contrast_magnitude': max_contrast,\n",
    "                        'label_differences': performance_diff,\n",
    "                        'scores': {\n",
    "                            comp1: competitor_label_scores[comp1],\n",
    "                            comp2: competitor_label_scores[comp2]\n",
    "                        }\n",
    "                    })\n",
    "    \n",
    "    # Sort cases by contrast magnitude\n",
    "    interesting_cases.sort(key=lambda x: x['contrast_magnitude'], reverse=True)\n",
    "    return interesting_cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5bc994f-bb71-400a-be97-6a1b7924fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the start of your analysis, when loading the data:\n",
    "df['J_value'] = pd.to_numeric(df['J_value'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bca3959f-7b32-4b47-9cbe-7614770f52b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Contrasting Performance Cases:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Case 1:\n",
      "Image: t1748.tif\n",
      "Competitors: CALT-US vs KIT-Sch-GE\n",
      "Contrast Magnitude: 0.921\n",
      "153     0.754875\n",
      "154     0.814249\n",
      "155     0.914634\n",
      "156     0.820896\n",
      "157     0.843511\n",
      "          ...   \n",
      "3124    0.860465\n",
      "3125    0.879630\n",
      "3126    0.902208\n",
      "3127    0.830729\n",
      "3128    0.890380\n",
      "Name: J_value, Length: 918, dtype: float64\n",
      "Saved plot: case_1_t1748_tif_all_competitors.png\n",
      "153     0.754875\n",
      "154     0.814249\n",
      "155     0.914634\n",
      "156     0.820896\n",
      "157     0.843511\n",
      "          ...   \n",
      "3124    0.860465\n",
      "3125    0.879630\n",
      "3126    0.902208\n",
      "3127    0.830729\n",
      "3128    0.890380\n",
      "Name: J_value, Length: 918, dtype: float64\n",
      "Saved plot: case_1_t1748_tif_contrasting_pair.png\n",
      "153     0.754875\n",
      "154     0.814249\n",
      "155     0.914634\n",
      "156     0.820896\n",
      "157     0.843511\n",
      "          ...   \n",
      "3124    0.860465\n",
      "3125    0.879630\n",
      "3126    0.902208\n",
      "3127    0.830729\n",
      "3128    0.890380\n",
      "Name: J_value, Length: 918, dtype: float64\n",
      "Saved plot: case_1_t1748_tif_all_with_silver.png\n",
      "153     0.754875\n",
      "154     0.814249\n",
      "155     0.914634\n",
      "156     0.820896\n",
      "157     0.843511\n",
      "          ...   \n",
      "3124    0.860465\n",
      "3125    0.879630\n",
      "3126    0.902208\n",
      "3127    0.830729\n",
      "3128    0.890380\n",
      "Name: J_value, Length: 918, dtype: float64\n",
      "Saved plot: case_1_t1748_tif_silver_highlighted.png\n",
      "153     0.754875\n",
      "154     0.814249\n",
      "155     0.914634\n",
      "156     0.820896\n",
      "157     0.843511\n",
      "          ...   \n",
      "3124    0.860465\n",
      "3125    0.879630\n",
      "3126    0.902208\n",
      "3127    0.830729\n",
      "3128    0.890380\n",
      "Name: J_value, Length: 918, dtype: float64\n",
      "Saved plot: case_1_t1748_tif_best_highlighted.png\n",
      "\n",
      "Case 2:\n",
      "Image: t1585.tif\n",
      "Competitors: KIT-Sch-GE vs MU-Lux-CZ\n",
      "Contrast Magnitude: 0.856\n",
      "48      0.801120\n",
      "49      0.833333\n",
      "50      0.791209\n",
      "51      0.812298\n",
      "52      0.854701\n",
      "          ...   \n",
      "2968    0.843636\n",
      "2969    0.732203\n",
      "2970    0.851590\n",
      "2971    0.897959\n",
      "2972    0.863787\n",
      "Name: J_value, Length: 614, dtype: float64\n",
      "Saved plot: case_2_t1585_tif_all_competitors.png\n",
      "48      0.801120\n",
      "49      0.833333\n",
      "50      0.791209\n",
      "51      0.812298\n",
      "52      0.854701\n",
      "          ...   \n",
      "2968    0.843636\n",
      "2969    0.732203\n",
      "2970    0.851590\n",
      "2971    0.897959\n",
      "2972    0.863787\n",
      "Name: J_value, Length: 614, dtype: float64\n",
      "Saved plot: case_2_t1585_tif_contrasting_pair.png\n",
      "48      0.801120\n",
      "49      0.833333\n",
      "50      0.791209\n",
      "51      0.812298\n",
      "52      0.854701\n",
      "          ...   \n",
      "2968    0.843636\n",
      "2969    0.732203\n",
      "2970    0.851590\n",
      "2971    0.897959\n",
      "2972    0.863787\n",
      "Name: J_value, Length: 614, dtype: float64\n",
      "Saved plot: case_2_t1585_tif_all_with_silver.png\n",
      "48      0.801120\n",
      "49      0.833333\n",
      "50      0.791209\n",
      "51      0.812298\n",
      "52      0.854701\n",
      "          ...   \n",
      "2968    0.843636\n",
      "2969    0.732203\n",
      "2970    0.851590\n",
      "2971    0.897959\n",
      "2972    0.863787\n",
      "Name: J_value, Length: 614, dtype: float64\n",
      "Saved plot: case_2_t1585_tif_silver_highlighted.png\n",
      "48      0.801120\n",
      "49      0.833333\n",
      "50      0.791209\n",
      "51      0.812298\n",
      "52      0.854701\n",
      "          ...   \n",
      "2968    0.843636\n",
      "2969    0.732203\n",
      "2970    0.851590\n",
      "2971    0.897959\n",
      "2972    0.863787\n",
      "Name: J_value, Length: 614, dtype: float64\n",
      "Saved plot: case_2_t1585_tif_best_highlighted.png\n",
      "\n",
      "Case 3:\n",
      "Image: t1585.tif\n",
      "Competitors: DREX-US vs KIT-Sch-GE\n",
      "Contrast Magnitude: 0.798\n",
      "48      0.801120\n",
      "49      0.833333\n",
      "50      0.791209\n",
      "51      0.812298\n",
      "52      0.854701\n",
      "          ...   \n",
      "2968    0.843636\n",
      "2969    0.732203\n",
      "2970    0.851590\n",
      "2971    0.897959\n",
      "2972    0.863787\n",
      "Name: J_value, Length: 614, dtype: float64\n",
      "Saved plot: case_3_t1585_tif_all_competitors.png\n",
      "48      0.801120\n",
      "49      0.833333\n",
      "50      0.791209\n",
      "51      0.812298\n",
      "52      0.854701\n",
      "          ...   \n",
      "2968    0.843636\n",
      "2969    0.732203\n",
      "2970    0.851590\n",
      "2971    0.897959\n",
      "2972    0.863787\n",
      "Name: J_value, Length: 614, dtype: float64\n",
      "Saved plot: case_3_t1585_tif_contrasting_pair.png\n",
      "48      0.801120\n",
      "49      0.833333\n",
      "50      0.791209\n",
      "51      0.812298\n",
      "52      0.854701\n",
      "          ...   \n",
      "2968    0.843636\n",
      "2969    0.732203\n",
      "2970    0.851590\n",
      "2971    0.897959\n",
      "2972    0.863787\n",
      "Name: J_value, Length: 614, dtype: float64\n",
      "Saved plot: case_3_t1585_tif_all_with_silver.png\n",
      "48      0.801120\n",
      "49      0.833333\n",
      "50      0.791209\n",
      "51      0.812298\n",
      "52      0.854701\n",
      "          ...   \n",
      "2968    0.843636\n",
      "2969    0.732203\n",
      "2970    0.851590\n",
      "2971    0.897959\n",
      "2972    0.863787\n",
      "Name: J_value, Length: 614, dtype: float64\n",
      "Saved plot: case_3_t1585_tif_silver_highlighted.png\n",
      "48      0.801120\n",
      "49      0.833333\n",
      "50      0.791209\n",
      "51      0.812298\n",
      "52      0.854701\n",
      "          ...   \n",
      "2968    0.843636\n",
      "2969    0.732203\n",
      "2970    0.851590\n",
      "2971    0.897959\n",
      "2972    0.863787\n",
      "Name: J_value, Length: 614, dtype: float64\n",
      "Saved plot: case_3_t1585_tif_best_highlighted.png\n"
     ]
    }
   ],
   "source": [
    "cases, enhanced_df = analyze_contrasting_performance(df, overall_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5739e-aa94-4a58-a6f6-988c30020c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
